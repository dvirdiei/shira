#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Migration script from CSV to Supabase for ×”× ×•×¡×¢ ×”××ª××™×“
××™×’×¨×¦×™×” ×™×©×™×¨×” ×¢× ×”×¤×¨×˜×™× ×”××•×›× ×™×
"""

import os
import sys
import pandas as pd
import logging
from typing import List, Dict
from datetime import datetime

# ×”×•×¡×¤×ª × ×ª×™×‘ ×œ×—×™×¤×•×© ××•×“×•×œ×™×
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

# ×”×’×“×¨×ª ×œ×•×’×™× ×’
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def migrate_to_supabase_direct():
    """××™×’×¨×¦×™×” ×™×©×™×¨×” ×¢× ×¤×¨×˜×™ Supabase"""
    try:
        logger.info("ğŸš€ ××ª×—×™×œ ××™×’×¨×¦×™×” ×œ-Supabase...")
        
        # ×¤×¨×˜×™ Supabase ×™×©×™×¨×•×ª
        url = "https://ivhmndizihxskjhlqaki.supabase.co"
        key = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Iml2aG1uZGl6aWh4c2tqaGxxYWtpIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1MTgzMTQ1MiwiZXhwIjoyMDY3NDA3NDUyfQ.WqHjgDitX_cgR_s36LoXHtps34l2Y2_3-5weACVFcus"
        
        # 1. ×—×™×‘×•×¨ ×œSupabase
        from supabase import create_client, Client
        supabase: Client = create_client(url, key)
        logger.info("âœ… ×”×ª×—×‘×¨ ×œSupabase")
        
        # 2. ×§×¨×™××ª × ×ª×•× ×™× ×-CSV
        logger.info("ğŸ“– ×§×•×¨× × ×ª×•× ×™× ×-CSV...")
        addresses = read_csv_files()
        
        if not addresses:
            logger.error("âŒ ×œ× × ××¦××• ×›×ª×•×‘×•×ª ×œ×¢×™×¤×•")
            return False
        
        # 3. ×‘×“×™×§×” ×× ×›×‘×¨ ×™×© × ×ª×•× ×™×
        result = supabase.table('addresses').select("*").limit(1).execute()
        if result.data:
            logger.warning(f"âš ï¸  × ××¦××• {len(result.data)} ×›×ª×•×‘×•×ª ×§×™×™××•×ª")
            response = input("×”×× ×œ××—×•×§ ×•×œ×”×ª×—×™×œ ××—×“×©? (y/N): ")
            if response.lower() == 'y':
                delete_result = supabase.table('addresses').delete().neq('id', 0).execute()
                logger.info("ğŸ—‘ï¸  × ×ª×•× ×™× ×§×™×™××™× × ××—×§×•")
            else:
                logger.info("âŒ ×‘×™×˜×•×œ ××™×’×¨×¦×™×”")
                return False
        
        # 4. ×”×¢×‘×¨×ª × ×ª×•× ×™× ×‘×§×‘×•×¦×•×ª
        batch_size = 50  # ×§×˜×Ÿ ×™×•×ª×¨ ×œSupabase
        total_inserted = 0
        
        for i in range(0, len(addresses), batch_size):
            batch = addresses[i:i + batch_size]
            logger.info(f"××¢×‘×™×¨ ×§×‘×•×¦×” {i//batch_size + 1}: ×›×ª×•×‘×•×ª {i+1}-{min(i+batch_size, len(addresses))}")
            
            try:
                insert_result = supabase.table('addresses').insert(batch).execute()
                if insert_result.data:
                    total_inserted += len(insert_result.data)
                    logger.info(f"âœ… ×”×•×¢×‘×¨×• {len(insert_result.data)} ×›×ª×•×‘×•×ª")
                else:
                    logger.error(f"âŒ ×©×’×™××” ×‘×”×¢×‘×¨×ª ×§×‘×•×¦×” {i//batch_size + 1}")
            except Exception as e:
                logger.error(f"âŒ ×©×’×™××” ×‘×§×‘×•×¦×” {i//batch_size + 1}: {e}")
        
        # 5. ×¡×™×›×•×
        logger.info(f"âœ… ××™×’×¨×¦×™×” ×”×•×©×œ××”!")
        logger.info(f"ğŸ“Š ×”×•×¢×‘×¨×• {total_inserted} ×›×ª×•×‘×•×ª ××ª×•×š {len(addresses)}")
        
        # 6. ×¡×˜×˜×™×¡×˜×™×§×•×ª
        final_result = supabase.table('addresses').select("*").execute()
        logger.info(f"ğŸ“ˆ ×¡×”\"×› ×›×ª×•×‘×•×ª ×‘Supabase: {len(final_result.data) if final_result.data else 0}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ×©×’×™××” ×‘××™×’×¨×¦×™×”: {e}")
        return False

def read_csv_files() -> List[Dict]:
    """×§×¨×™××ª ×›×œ ×§×‘×¦×™ ×”-CSV"""
    database_dir = os.path.join(os.path.dirname(__file__), 'database')
    all_addresses = []
    
    csv_files = [
        'addresses_cleaned.csv',
        'addresses_geocoded.csv',
        'addresses.csv'  # ×‘×¡×™×¡×™
    ]
    
    for csv_file in csv_files:
        file_path = os.path.join(database_dir, csv_file)
        
        if os.path.exists(file_path):
            try:
                logger.info(f"×§×•×¨× ×§×•×‘×¥: {csv_file}")
                df = pd.read_csv(file_path, encoding='utf-8')
                
                # ×”××¨×” ×œ×¨×©×™××ª dictionaries
                for _, row in df.iterrows():
                    address_data = {
                        'address': str(row.get('address', '')).strip(),
                        'city': str(row.get('city', '')).strip(),
                        'latitude': row.get('latitude') if pd.notna(row.get('latitude')) else None,
                        'longitude': row.get('longitude') if pd.notna(row.get('longitude')) else None,
                        'source_file': csv_file,
                        'created_at': datetime.now().isoformat()
                    }
                    
                    # ×”×•×¡×¤×” ×¨×§ ×× ×™×© ×›×ª×•×‘×ª
                    if address_data['address'] and address_data['address'] != 'nan':
                        all_addresses.append(address_data)
                
                logger.info(f"× ××¦××• {len(df)} ×›×ª×•×‘×•×ª ×‘-{csv_file}")
                
            except Exception as e:
                logger.error(f"×©×’×™××” ×‘×§×¨×™××ª {csv_file}: {e}")
        else:
            logger.warning(f"×§×•×‘×¥ ×œ× × ××¦×: {csv_file}")
    
    # ×”×¡×¨×ª ×›×¤×™×œ×•×™×•×ª
    unique_addresses = []
    seen_addresses = set()
    
    for addr in all_addresses:
        # ×™×¦×™×¨×ª ××¤×ª×— ×™×™×—×•×“×™
        key = f"{addr['address'].lower()}_{addr['city'].lower()}"
        
        if key not in seen_addresses:
            seen_addresses.add(key)
            unique_addresses.append(addr)
    
    logger.info(f"×¡×”\"×› ×›×ª×•×‘×•×ª ×™×™×—×•×“×™×•×ª: {len(unique_addresses)}")
    return unique_addresses

def migrate_to_supabase():
    """××™×’×¨×¦×™×” ×¢×™×§×¨×™×ª ×œ-Supabase"""
    try:
        logger.info("ğŸš€ ××ª×—×™×œ ××™×’×¨×¦×™×” ×œ-Supabase...")
        
        # 1. ×‘×“×™×§×ª ×—×™×‘×•×¨
        handler = get_supabase_handler()
        if not handler.test_connection():
            logger.error("âŒ ×œ× × ×™×ª×Ÿ ×œ×”×ª×—×‘×¨ ×œ-Supabase")
            return False
        
        # 2. ×§×¨×™××ª × ×ª×•× ×™× ×-CSV
        logger.info("ğŸ“– ×§×•×¨× × ×ª×•× ×™× ×-CSV...")
        addresses = read_csv_files()
        
        if not addresses:
            logger.error("âŒ ×œ× × ××¦××• ×›×ª×•×‘×•×ª ×œ×¢×™×¤×•")
            return False
        
        # 3. ×‘×“×™×§×” ×× ×›×‘×¨ ×™×© × ×ª×•× ×™×
        existing_addresses = handler.get_all_addresses()
        if existing_addresses:
            logger.warning(f"âš ï¸  × ××¦××• {len(existing_addresses)} ×›×ª×•×‘×•×ª ×§×™×™××•×ª")
            response = input("×”×× ×œ××—×•×§ ×•×œ×”×ª×—×™×œ ××—×“×©? (y/N): ")
            if response.lower() == 'y':
                handler.delete_all_addresses()
                logger.info("ğŸ—‘ï¸  × ×ª×•× ×™× ×§×™×™××™× × ××—×§×•")
            else:
                logger.info("âŒ ×‘×™×˜×•×œ ××™×’×¨×¦×™×”")
                return False
        
        # 4. ×”×¢×‘×¨×ª × ×ª×•× ×™× ×‘×§×‘×•×¦×•×ª
        batch_size = 100
        total_inserted = 0
        
        for i in range(0, len(addresses), batch_size):
            batch = addresses[i:i + batch_size]
            logger.info(f"××¢×‘×™×¨ ×§×‘×•×¦×” {i//batch_size + 1}: ×›×ª×•×‘×•×ª {i+1}-{min(i+batch_size, len(addresses))}")
            
            if handler.insert_addresses_batch(batch):
                total_inserted += len(batch)
            else:
                logger.error(f"âŒ ×©×’×™××” ×‘×”×¢×‘×¨×ª ×§×‘×•×¦×” {i//batch_size + 1}")
        
        # 5. ×¡×™×›×•×
        logger.info(f"âœ… ××™×’×¨×¦×™×” ×”×•×©×œ××”!")
        logger.info(f"ğŸ“Š ×”×•×¢×‘×¨×• {total_inserted} ×›×ª×•×‘×•×ª ××ª×•×š {len(addresses)}")
        
        # 6. ×¡×˜×˜×™×¡×˜×™×§×•×ª
        stats = handler.get_statistics()
        logger.info(f"ğŸ“ˆ ×¡×˜×˜×™×¡×˜×™×§×•×ª ×¡×•×¤×™×•×ª: {stats}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ×©×’×™××” ×‘××™×’×¨×¦×™×”: {e}")
        return False

def verify_migration():
    """××™××•×ª ×©×”××™×’×¨×¦×™×” ×”×¦×œ×™×—×”"""
    try:
        logger.info("ğŸ” ××××ª ××™×’×¨×¦×™×”...")
        
        handler = get_supabase_handler()
        stats = handler.get_statistics()
        
        print("\n" + "="*50)
        print("ğŸ“Š ×¡×™×›×•× ××™×’×¨×¦×™×”")
        print("="*50)
        print(f"ğŸ“ ×¡×”\"×› ×›×ª×•×‘×•×ª: {stats['total_addresses']}")
        print(f"ğŸŒ ×›×ª×•×‘×•×ª ×¢× ×§×•××•×¨×“×™× ×˜×•×ª: {stats['geocoded_addresses']}")
        print(f"â³ ×›×ª×•×‘×•×ª ×××ª×™× ×•×ª ×œ×’×™××•×§×•×“×™× ×’: {stats['pending_geocoding']}")
        print(f"ğŸ“Š ××—×•×– ×’×™××•×§×•×“×™× ×’: {stats['geocoded_percentage']}%")
        print("="*50)
        
        if stats['total_addresses'] > 0:
            print("âœ… ××™×’×¨×¦×™×” ×”×•×©×œ××” ×‘×”×¦×œ×—×”!")
            return True
        else:
            print("âŒ ×œ× × ××¦××• × ×ª×•× ×™× ××—×¨×™ ×”××™×’×¨×¦×™×”")
            return False
            
    except Exception as e:
        logger.error(f"âŒ ×©×’×™××” ×‘××™××•×ª: {e}")
        return False

if __name__ == "__main__":
    print("ğŸš€ ××™×’×¨×¦×™×” ×œ-Supabase - ×”× ×•×¡×¢ ×”××ª××™×“")
    print("="*50)
    
    # ×”×¨×¦×ª ××™×’×¨×¦×™×”
    if migrate_to_supabase_direct():
        print("âœ… ×”××™×’×¨×¦×™×” ×”×•×©×œ××” ×‘×”×¦×œ×—×”!")
    else:
        print("âŒ ×”××™×’×¨×¦×™×” × ×›×©×œ×”")
